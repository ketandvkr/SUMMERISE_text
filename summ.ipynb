{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for calling Coats and Gowns, my name is Sam, how can I help you? Yes, I bought a coat from you guys but I need to return it because it was the wrong size and my size is not available. I haven't received any email from you and I wonder if my payment has been refunded. Seems like it does not apply on my account yet. I do apologize for the inconvenience but let me go ahead and check if there are some notes in the order details. May I ask for the original online order number? Okay, let me see, please wait for a moment. Okay I believe it's 017-1425-793. Thank you, just to verify that's 017-1425-793, correct? Yes, that's right. I do apologize but the one that you provided is actually not accepting towards our database. Do you actually have a number that starts with 0007 or 7? Or can I ask for your first and last name so I can manually check it in our database? Yeah, I'm not sure about a 000 something, anyway it's Adam Wilson. Alright, thank you. So Wilson is spelled as W for Whiskey, I for India, L for Lima, S for Sierra, O for Oscar and N for November. Is that correct Adam? Yes. Alright, thank you for that information. Okay, let me just quickly log into a portal and check any notes in your order. Do you still have the return tracking from the courier company when you return the item? Not sure, is it the 74391? That's actually the return authorization from Coats and Gowns. When you return the item to the courier company for shipping, they should have provided you with the return tracking. Do you still have that? It's actually printed in the upper right part of the receipt. Okay, I probably have to dig it up. Okay, I imagine I have it somewhere but it might take some time to look for that. Oh, I see. Anyway I tried to search for your name and nothing is coming up. Can I ask for the order under your name originally? Yes, it's under my name. So it's not under Andy or something? It's Adam? Yes, exactly. Thank you. Now what's the phone number that you put on the order before? Okay, probably it's 411-345-0377. Thank you. It's 411-345-0377, is that correct? Oh, it's 0377. Okay, and what's the email address that you gave when you fill out the order form? Okay, that should be Adam underscore Wilson at MailFence.com. Thank you. So again, it's Adam underscore Wilson at MailFence.com, is that correct? Yes, it is. Thank you. So Adam underscore Wilson at MailFence.com. Okay, thank you. Now I just want to make sure that I have the correct details. Please hold on for a moment while I check on the details here on my end, okay? Oh sure, no problem. Alright. Okay, thank you for patiently waiting, Adam. Now I can actually see here that you have called to inform us that you'd like to return the item on the 15th of November. Is that correct? Yes. Now did you return the item to the courier company on the same day that you called? Probably close to it. I'm not really sure if it's on the same day though, but probably just close to that day. I understand. However, upon checking the date that you actually called in for the return, it's already beyond the time frame that we asked for refunds. So what we'll do is I'll go ahead and forward this information to our corporate office and I'll have them check and update you directly about the refund. So please expect an email within two to four business days. Is that okay with you? Two to four business days? Yes. No worries, I will send it to them right now. Oh really? Okay. Alright, alright. At first I thought that it will probably be like three to five weeks to process. Oh, no, no, no. Don't worry, Adam. It's only two to four business days. So you already checked your account and nothing has been credited yet on the card ending in 753? Is that right? Nothing yet. Okay, I understand. And I'll go ahead and forward in the details that I have here. So I'll send the email to Adam underscore Wilson at MailFence.com, correct? Yes, that's right. Alright, thank you so much for that information, Adam. I will be forwarding this over to our corporate office now. And thank you again for calling Coats and Gowns. Is there anything else I can help you with today? Oh, no, that's all. Thank you. You're welcome. My pleasure. Have a nice day. Bye. Alright, thank you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "with open(r\"E:/myapp/whispweai/nig.mp3\", \"rb\") as audio_file:\n",
    "    transcript1 = openai.Audio.transcribe(\n",
    "        file = audio_file,\n",
    "        model = \"whisper-1\",\n",
    "        response_format=\"text\",\n",
    "        language=\"en\"\n",
    "    )\n",
    "print(transcript1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1: Thank you for calling Coats and Gowns, my name is Sam, how can I help you? Yes, I bought a coat from you guys but I need to return it because it was the wrong size and my size is not available. I haven't received any email from you and I wonder if my payment has been refunded. Seems like it does not apply on my account yet. I do apologize for the inconvenience but let me go ahead and check if there are some notes in the \n",
      "Part 2: order details. May I ask for the original online order number? Okay, let me see, please wait for a moment. Okay I believe it's 017-1425-793. Thank you, just to verify that's 017-1425-793, correct? Yes, that's right. I do apologize but the one that you provided is actually not accepting towards our database. Do you actually have a number that starts with 0007 or 7? Or can I ask for your first and last name so I can manual\n",
      "Part 3: ly check it in our database? Yeah, I'm not sure about a 000 something, anyway it's Adam Wilson. Alright, thank you. So Wilson is spelled as W for Whiskey, I for India, L for Lima, S for Sierra, O for Oscar and N for November. Is that correct Adam? Yes. Alright, thank you for that information. Okay, let me just quickly log into a portal and check any notes in your order. Do you still have the return tracking from the cour\n",
      "Part 4: ier company when you return the item? Not sure, is it the 74391? That's actually the return authorization from Coats and Gowns. When you return the item to the courier company for shipping, they should have provided you with the return tracking. Do you still have that? It's actually printed in the upper right part of the receipt. Okay, I probably have to dig it up. Okay, I imagine I have it somewhere but it might take so\n",
      "Part 5: me time to look for that. Oh, I see. Anyway I tried to search for your name and nothing is coming up. Can I ask for the order under your name originally? Yes, it's under my name. So it's not under Andy or something? It's Adam? Yes, exactly. Thank you. Now what's the phone number that you put on the order before? Okay, probably it's 411-345-0377. Thank you. It's 411-345-0377, is that correct? Oh, it's 0377. Okay, and what\n",
      "Part 6: 's the email address that you gave when you fill out the order form? Okay, that should be Adam underscore Wilson at MailFence.com. Thank you. So again, it's Adam underscore Wilson at MailFence.com, is that correct? Yes, it is. Thank you. So Adam underscore Wilson at MailFence.com. Okay, thank you. Now I just want to make sure that I have the correct details. Please hold on for a moment while I check on the details here o\n",
      "Part 7: n my end, okay? Oh sure, no problem. Alright. Okay, thank you for patiently waiting, Adam. Now I can actually see here that you have called to inform us that you'd like to return the item on the 15th of November. Is that correct? Yes. Now did you return the item to the courier company on the same day that you called? Probably close to it. I'm not really sure if it's on the same day though, but probably just close to that\n",
      "Part 8:  day. I understand. However, upon checking the date that you actually called in for the return, it's already beyond the time frame that we asked for refunds. So what we'll do is I'll go ahead and forward this information to our corporate office and I'll have them check and update you directly about the refund. So please expect an email within two to four business days. Is that okay with you? Two to four business days? Ye\n",
      "Part 9: s. No worries, I will send it to them right now. Oh really? Okay. Alright, alright. At first I thought that it will probably be like three to five weeks to process. Oh, no, no, no. Don't worry, Adam. It's only two to four business days. So you already checked your account and nothing has been credited yet on the card ending in 753? Is that right? Nothing yet. Okay, I understand. And I'll go ahead and forward in the detai\n",
      "Part 10: ls that I have here. So I'll send the email to Adam underscore Wilson at MailFence.com, correct? Yes, that's right. Alright, thank you so much for that information, Adam. I will be forwarding this over to our corporate office now. And thank you again for calling Coats and Gowns. Is there anything else I can help you with today? Oh, no, that's all. Thank you. You're welcome. My pleasure. Have a nice day. Bye. Alright, tha\n",
      "Part 11: nk you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_string = (transcript1)\n",
    "\n",
    "# Define the number of parts\n",
    "num_parts = 500\n",
    "\n",
    "# Calculate the approximate length of each part\n",
    "part_length = len(input_string) // 10\n",
    "\n",
    "# Initialize an empty list to store the parts\n",
    "parts_list = []\n",
    "\n",
    "# Split the input string into parts and append them to the list\n",
    "for i in range(0, len(input_string), part_length):\n",
    "    part = input_string[i:i+part_length]\n",
    "    parts_list.append(part)\n",
    "\n",
    "# If there's a remainder, add it to the last part\n",
    "if len(parts_list) < num_parts:\n",
    "    parts_list[-1] += input_string[len(parts_list) * part_length:]\n",
    "\n",
    "# Print or use the parts_list as needed\n",
    "for i, part in enumerate(parts_list):\n",
    "    print(f\"Part {i+1}: {part}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thank you for calling Coats and Gowns, my name is Sam, how can I help you? Yes, I bought a coat from you guys but I need to return it because it was the wrong size and my size is not available. I haven't received any email from you and I wonder if my payment has been refunded. Seems like it does not apply on my account yet. I do apologize for the inconvenience but let me go ahead and check if there are some notes in the order details. May I ask for the original online order number? Okay, let me see, please wait for a moment. Okay I believe it's 017-1425-793. Thank you, just to verify that's 017-1425-793, correct? Yes, that's right. I do apologize but the one that you provided is actually not accepting towards our database. Do you actually have a number that starts with 0007 or 7? Or can I ask for your first and last name so I can manually check it in our database? Yeah, I'm not sure about a 000 something, anyway it's Adam Wilson. Alright, thank you. So Wilson is spelled as W for Whiskey, I for India, L for Lima, S for Sierra, O for Oscar and N for November. Is that correct Adam? Yes. Alright, thank you for that information. Okay, let me just quickly log into a portal and check any notes in your order. Do you still have the return tracking from the courier company when you return the item? Not sure, is it the 74391? That's actually the return authorization from Coats and Gowns. When you return the item to the courier company for shipping, they should have provided you with the return tracking. Do you still have that? It's actually printed in the upper right part of the receipt. Okay, I probably have to dig it up. Okay, I imagine I have it somewhere but it might take some time to look for that. Oh, I see. Anyway I tried to search for your name and nothing is coming up. Can I ask for the order under your name originally? Yes, it's under my name. So it's not under Andy or something? It's Adam? Yes, exactly. Thank you. Now what's the phone number that you put on the order before? Okay, probably it's 411-345-0377. Thank you. It's 411-345-0377, is that correct? Oh, it's 0377. Okay, and what's the email address that you gave when you fill out the order form? Okay, that should be Adam underscore Wilson at MailFence.com. Thank you. So again, it's Adam underscore Wilson at MailFence.com, is that correct? Yes, it is. Thank you. So Adam underscore Wilson at MailFence.com. Okay, thank you. Now I just want to make sure that I have the correct details. Please hold on for a moment while I check on the details here on my end, okay? Oh sure, no problem. Alright. Okay, thank you for patiently waiting, Adam. Now I can actually see here that you have called to inform us that you'd like to return the item on the 15th of November. Is that correct? Yes. Now did you return the item to the courier company on the same day that you called? Probably close to it. I'm not really sure if it's on the same day though, but probably just close to that day. I understand. However, upon checking the date that you actually called in for the return, it's already beyond the time frame that we asked for refunds. So what we'll do is I'll go ahead and forward this information to our corporate office and I'll have them check and update you directly about the refund. So please expect an email within two to four business days. Is that okay with you? Two to four business days? Yes. No worries, I will send it to them right now. Oh really? Okay. Alright, alright. At first I thought that it will probably be like three to five weeks to process. Oh, no, no, no. Don't worry, Adam. It's only two to four business days. So you already checked your account and nothing has been credited yet on the card ending in 753? Is that right? Nothing yet. Okay, I understand. And I'll go ahead and forward in the details that I have here. So I'll send the email to Adam underscore Wilson at MailFence.com, correct? Yes, that's right. Alright, thank you so much for that information, Adam. I will be forwarding this over to our corporate office now. And thank you again for calling Coats and Gowns. Is there anything else I can help you with today? Oh, no, that's all. Thank you. You're welcome. My pleasure. Have a nice day. Bye. Alright, thank you.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 205881344 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m summ\u001b[39m=\u001b[39mpipeline(\u001b[39m'\u001b[39;49m\u001b[39msummarization\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:788\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    787\u001b[0m     model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m--> 788\u001b[0m     framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    789\u001b[0m         model,\n\u001b[0;32m    790\u001b[0m         model_classes\u001b[39m=\u001b[39;49mmodel_classes,\n\u001b[0;32m    791\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m    792\u001b[0m         framework\u001b[39m=\u001b[39;49mframework,\n\u001b[0;32m    793\u001b[0m         task\u001b[39m=\u001b[39;49mtask,\n\u001b[0;32m    794\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs,\n\u001b[0;32m    795\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[0;32m    796\u001b[0m     )\n\u001b[0;32m    798\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    799\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\transformers\\pipelines\\base.py:269\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    264\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    265\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTrying to load the model with Tensorflow.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m     )\n\u001b[0;32m    268\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 269\u001b[0m     model \u001b[39m=\u001b[39m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39meval\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    271\u001b[0m         model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:493\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    492\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[0;32m    494\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    495\u001b[0m     )\n\u001b[0;32m    496\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    497\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    498\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m )\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\transformers\\modeling_utils.py:2700\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2697\u001b[0m     init_contexts\u001b[39m.\u001b[39mappend(init_empty_weights())\n\u001b[0;32m   2699\u001b[0m \u001b[39mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m-> 2700\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(config, \u001b[39m*\u001b[39;49mmodel_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs)\n\u001b[0;32m   2702\u001b[0m \u001b[39m# Check first if we are `from_pt`\u001b[39;00m\n\u001b[0;32m   2703\u001b[0m \u001b[39mif\u001b[39;00m use_keep_in_fp32_modules:\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1306\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m   1304\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config: BartConfig):\n\u001b[0;32m   1305\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(config)\n\u001b[1;32m-> 1306\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m BartModel(config)\n\u001b[0;32m   1307\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister_buffer(\u001b[39m\"\u001b[39m\u001b[39mfinal_logits_bias\u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mshared\u001b[39m.\u001b[39mnum_embeddings)))\n\u001b[0;32m   1308\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(config\u001b[39m.\u001b[39md_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mshared\u001b[39m.\u001b[39mnum_embeddings, bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1182\u001b[0m, in \u001b[0;36mBartModel.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m   1179\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshared \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(vocab_size, config\u001b[39m.\u001b[39md_model, padding_idx)\n\u001b[0;32m   1181\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m BartEncoder(config, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshared)\n\u001b[1;32m-> 1182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder \u001b[39m=\u001b[39m BartDecoder(config, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshared)\n\u001b[0;32m   1184\u001b[0m \u001b[39m# Initialize weights and apply final processing\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_init()\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:902\u001b[0m, in \u001b[0;36mBartDecoder.__init__\u001b[1;34m(self, config, embed_tokens)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_target_positions \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mmax_position_embeddings\n\u001b[0;32m    900\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_scale \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39msqrt(config\u001b[39m.\u001b[39md_model) \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mscale_embedding \u001b[39melse\u001b[39;00m \u001b[39m1.0\u001b[39m\n\u001b[1;32m--> 902\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mEmbedding(config\u001b[39m.\u001b[39;49mvocab_size, config\u001b[39m.\u001b[39;49md_model, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx)\n\u001b[0;32m    904\u001b[0m \u001b[39mif\u001b[39;00m embed_tokens \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    905\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m embed_tokens\u001b[39m.\u001b[39mweight\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:142\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[1;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_grad_by_freq \u001b[39m=\u001b[39m scale_grad_by_freq\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m _weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39;49mempty((num_embeddings, embedding_dim), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfactory_kwargs),\n\u001b[0;32m    143\u001b[0m                             requires_grad\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m _freeze)\n\u001b[0;32m    144\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_parameters()\n\u001b[0;32m    145\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 205881344 bytes."
     ]
    }
   ],
   "source": [
    "summ=pipeline('summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ(part[0],max_length=150, min_length=20,do_sample=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2349368318756074\n"
     ]
    }
   ],
   "source": [
    "analysis=TextBlob(transcript1)\n",
    "print(analysis.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment :positive\n"
     ]
    }
   ],
   "source": [
    "print(f'sentiment :{\"positive\"if analysis.polarity>0 else \"negative\" if analysis.polarity<0 else \"Neutral\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('for', 'IN'),\n",
       " ('calling', 'VBG'),\n",
       " ('Coats', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Gowns', 'NNP'),\n",
       " ('my', 'PRP$'),\n",
       " ('name', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('Sam', 'NNP'),\n",
       " ('how', 'WRB'),\n",
       " ('can', 'MD'),\n",
       " ('I', 'PRP'),\n",
       " ('help', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('Yes', 'UH'),\n",
       " ('I', 'PRP'),\n",
       " ('bought', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('coat', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('guys', 'VBP'),\n",
       " ('but', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('need', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('return', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('because', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('wrong', 'JJ'),\n",
       " ('size', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('my', 'PRP$'),\n",
       " ('size', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('available', 'JJ'),\n",
       " ('I', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('received', 'VBN'),\n",
       " ('any', 'DT'),\n",
       " ('email', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('and', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('wonder', 'VBP'),\n",
       " ('if', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('payment', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('refunded', 'VBN'),\n",
       " ('Seems', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('does', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('apply', 'VB'),\n",
       " ('on', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('account', 'NN'),\n",
       " ('yet', 'RB'),\n",
       " ('I', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " ('apologize', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('inconvenience', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('let', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('go', 'VB'),\n",
       " ('ahead', 'RB'),\n",
       " ('and', 'CC'),\n",
       " ('check', 'VB'),\n",
       " ('if', 'IN'),\n",
       " ('there', 'EX'),\n",
       " ('are', 'VBP'),\n",
       " ('some', 'DT'),\n",
       " ('notes', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('order', 'NN'),\n",
       " ('details', 'NNS'),\n",
       " ('May', 'NNP'),\n",
       " ('I', 'PRP'),\n",
       " ('ask', 'VBP'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('original', 'JJ'),\n",
       " ('online', 'NN'),\n",
       " ('order', 'NN'),\n",
       " ('number', 'NN'),\n",
       " ('Okay', 'NNP'),\n",
       " ('let', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('see', 'VB'),\n",
       " ('please', 'VB'),\n",
       " ('wait', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('moment', 'NN'),\n",
       " ('Okay', 'NNP'),\n",
       " ('I', 'PRP'),\n",
       " ('believe', 'VBP'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('017-1425-793', 'JJ'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('verify', 'VB'),\n",
       " ('that', 'DT'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('017-1425-793', 'JJ'),\n",
       " ('correct', 'VB'),\n",
       " ('Yes', 'UH'),\n",
       " ('that', 'DT'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('right', 'JJ'),\n",
       " ('I', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " ('apologize', 'VB'),\n",
       " ('but', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('one', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('you', 'PRP'),\n",
       " ('provided', 'VBD'),\n",
       " ('is', 'VBZ'),\n",
       " ('actually', 'RB'),\n",
       " ('not', 'RB'),\n",
       " ('accepting', 'VBG'),\n",
       " ('towards', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('database', 'NN'),\n",
       " ('Do', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('actually', 'RB'),\n",
       " ('have', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('number', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('starts', 'VBZ'),\n",
       " ('with', 'IN'),\n",
       " ('0007', 'CD'),\n",
       " ('or', 'CC'),\n",
       " ('7', 'CD'),\n",
       " ('Or', 'CC'),\n",
       " ('can', 'MD'),\n",
       " ('I', 'PRP'),\n",
       " ('ask', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('first', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('last', 'JJ'),\n",
       " ('name', 'NN'),\n",
       " ('so', 'RB'),\n",
       " ('I', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('manually', 'RB'),\n",
       " ('check', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('in', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('database', 'NN'),\n",
       " ('Yeah', 'UH'),\n",
       " ('I', 'PRP'),\n",
       " (\"'m\", 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('sure', 'JJ'),\n",
       " ('about', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('000', 'CD'),\n",
       " ('something', 'NN'),\n",
       " ('anyway', 'VBP'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('Adam', 'NNP'),\n",
       " ('Wilson', 'NNP'),\n",
       " ('Alright', 'NNP'),\n",
       " ('thank', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('So', 'RB'),\n",
       " ('Wilson', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('spelled', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('W', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('Whiskey', 'NNP'),\n",
       " ('I', 'PRP'),\n",
       " ('for', 'IN'),\n",
       " ('India', 'NNP'),\n",
       " ('L', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('Lima', 'NNP'),\n",
       " ('S', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('Sierra', 'NNP'),\n",
       " ('O', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('Oscar', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('N', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('November', 'NNP'),\n",
       " ('Is', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('correct', 'JJ'),\n",
       " ('Adam', 'NNP'),\n",
       " ('Yes', 'UH'),\n",
       " ('Alright', 'NNP'),\n",
       " ('thank', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('for', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('information', 'NN'),\n",
       " ('Okay', 'NNP'),\n",
       " ('let', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('quickly', 'RB'),\n",
       " ('log', 'VB'),\n",
       " ('into', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('portal', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('check', 'VB'),\n",
       " ('any', 'DT'),\n",
       " ('notes', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('order', 'NN'),\n",
       " ('Do', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('still', 'RB'),\n",
       " ('have', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('return', 'NN'),\n",
       " ('tracking', 'VBG'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('courier', 'NN'),\n",
       " ('company', 'NN'),\n",
       " ('when', 'WRB'),\n",
       " ('you', 'PRP'),\n",
       " ('return', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('item', 'NN'),\n",
       " ('Not', 'RB'),\n",
       " ('sure', 'JJ'),\n",
       " ('is', 'VBZ'),\n",
       " ('it', 'PRP'),\n",
       " ('the', 'DT'),\n",
       " ('74391', 'CD'),\n",
       " ('That', 'DT'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('actually', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('return', 'NN'),\n",
       " ('authorization', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('Coats', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Gowns', 'NNP'),\n",
       " ('When', 'WRB'),\n",
       " ('you', 'PRP'),\n",
       " ('return', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('item', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('courier', 'NN'),\n",
       " ('company', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('shipping', 'VBG'),\n",
       " ('they', 'PRP'),\n",
       " ('should', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('provided', 'VBN'),\n",
       " ('you', 'PRP'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('return', 'NN'),\n",
       " ('tracking', 'NN'),\n",
       " ('Do', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('still', 'RB'),\n",
       " ('have', 'VBP'),\n",
       " ('that', 'DT'),\n",
       " ('It', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('actually', 'RB'),\n",
       " ('printed', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('upper', 'JJ'),\n",
       " ('right', 'JJ'),\n",
       " ('part', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('receipt', 'NN'),\n",
       " ('Okay', 'NNP'),\n",
       " ('I', 'PRP'),\n",
       " ('probably', 'RB'),\n",
       " ('have', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('dig', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('up', 'RP'),\n",
       " ('Okay', 'NNP'),\n",
       " ('I', 'PRP'),\n",
       " ('imagine', 'VBP'),\n",
       " ('I', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('it', 'PRP'),\n",
       " ('somewhere', 'RB'),\n",
       " ('but', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('might', 'MD'),\n",
       " ('take', 'VB'),\n",
       " ('some', 'DT'),\n",
       " ('time', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('look', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('Oh', 'UH'),\n",
       " ('I', 'PRP'),\n",
       " ('see', 'VBP'),\n",
       " ('Anyway', 'RB'),\n",
       " ('I', 'PRP'),\n",
       " ('tried', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('search', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('name', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('nothing', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('coming', 'VBG'),\n",
       " ('up', 'RP'),\n",
       " ('Can', 'MD'),\n",
       " ('I', 'PRP'),\n",
       " ('ask', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('order', 'NN'),\n",
       " ('under', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('name', 'NN'),\n",
       " ('originally', 'RB'),\n",
       " ('Yes', 'UH'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('under', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('name', 'NN'),\n",
       " ('So', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('under', 'IN'),\n",
       " ('Andy', 'NNP'),\n",
       " ('or', 'CC'),\n",
       " ('something', 'NN'),\n",
       " ('It', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('Adam', 'NNP'),\n",
       " ('Yes', 'UH'),\n",
       " ('exactly', 'RB'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('Now', 'RB'),\n",
       " ('what', 'WP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('phone', 'NN'),\n",
       " ('number', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('put', 'VBP'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('order', 'NN'),\n",
       " ('before', 'IN'),\n",
       " ('Okay', 'NNP'),\n",
       " ('probably', 'RB'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('411-345-0377', 'JJ'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('It', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('411-345-0377', 'JJ'),\n",
       " ('is', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('correct', 'NN'),\n",
       " ('Oh', 'UH'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('0377', 'CD'),\n",
       " ('Okay', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('what', 'WP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('email', 'NN'),\n",
       " ('address', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('gave', 'VBD'),\n",
       " ('when', 'WRB'),\n",
       " ('you', 'PRP'),\n",
       " ('fill', 'VBP'),\n",
       " ('out', 'RP'),\n",
       " ('the', 'DT'),\n",
       " ('order', 'NN'),\n",
       " ('form', 'NN'),\n",
       " ('Okay', 'NNP'),\n",
       " ('that', 'WDT'),\n",
       " ('should', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('Adam', 'NNP'),\n",
       " ('underscore', 'IN'),\n",
       " ('Wilson', 'NNP'),\n",
       " ('at', 'IN'),\n",
       " ('MailFence.com', 'NNP'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('So', 'RB'),\n",
       " ('again', 'RB'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('Adam', 'NNP'),\n",
       " ('underscore', 'RB'),\n",
       " ('Wilson', 'NNP'),\n",
       " ('at', 'IN'),\n",
       " ('MailFence.com', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('correct', 'NN'),\n",
       " ('Yes', 'UH'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('So', 'RB'),\n",
       " ('Adam', 'NNP'),\n",
       " ('underscore', 'IN'),\n",
       " ('Wilson', 'NNP'),\n",
       " ('at', 'IN'),\n",
       " ('MailFence.com', 'NNP'),\n",
       " ('Okay', 'NNP'),\n",
       " ('thank', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('Now', 'RB'),\n",
       " ('I', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('want', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('make', 'VB'),\n",
       " ('sure', 'JJ'),\n",
       " ('that', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('correct', 'NN'),\n",
       " ('details', 'NNS'),\n",
       " ('Please', 'NNP'),\n",
       " ('hold', 'VB'),\n",
       " ('on', 'IN'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('moment', 'NN'),\n",
       " ('while', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('check', 'VBP'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('details', 'NNS'),\n",
       " ('here', 'RB'),\n",
       " ('on', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('end', 'NN'),\n",
       " ('okay', 'NN'),\n",
       " ('Oh', 'UH'),\n",
       " ('sure', 'JJ'),\n",
       " ('no', 'DT'),\n",
       " ('problem', 'NN'),\n",
       " ('Alright', 'NNP'),\n",
       " ('Okay', 'NNP'),\n",
       " ('thank', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('for', 'IN'),\n",
       " ('patiently', 'RB'),\n",
       " ('waiting', 'VBG'),\n",
       " ('Adam', 'NNP'),\n",
       " ('Now', 'RB'),\n",
       " ('I', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('actually', 'RB'),\n",
       " ('see', 'VB'),\n",
       " ('here', 'RB'),\n",
       " ('that', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('called', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('inform', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('that', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " (\"'d\", 'MD'),\n",
       " ('like', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('return', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('item', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('15th', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('November', 'NNP'),\n",
       " ('Is', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('correct', 'NN'),\n",
       " ('Yes', 'UH'),\n",
       " ('Now', 'RB'),\n",
       " ('did', 'VBD'),\n",
       " ('you', 'PRP'),\n",
       " ('return', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('item', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('courier', 'NN'),\n",
       " ('company', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('same', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('called', 'VBD'),\n",
       " ('Probably', 'RB'),\n",
       " ('close', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('it', 'PRP'),\n",
       " ('I', 'PRP'),\n",
       " (\"'m\", 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('really', 'RB'),\n",
       " ('sure', 'JJ'),\n",
       " ('if', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('same', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('though', 'IN'),\n",
       " ('but', 'CC'),\n",
       " ('probably', 'RB'),\n",
       " ('just', 'RB'),\n",
       " ('close', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('that', 'DT'),\n",
       " ('day', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('understand', 'VBP'),\n",
       " ('However', 'RB'),\n",
       " ('upon', 'IN'),\n",
       " ('checking', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('date', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('actually', 'RB'),\n",
       " ('called', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('return', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('already', 'RB'),\n",
       " ('beyond', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('time', 'NN'),\n",
       " ('frame', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('asked', 'VBD'),\n",
       " ('for', 'IN'),\n",
       " ('refunds', 'NNS'),\n",
       " ('So', 'RB'),\n",
       " ('what', 'WP'),\n",
       " ('we', 'PRP'),\n",
       " (\"'ll\", 'MD'),\n",
       " ('do', 'VB'),\n",
       " ('is', 'VBZ'),\n",
       " ('I', 'PRP'),\n",
       " (\"'ll\", 'MD'),\n",
       " ('go', 'VB'),\n",
       " ('ahead', 'RB'),\n",
       " ('and', 'CC'),\n",
       " ('forward', 'RB'),\n",
       " ('this', 'DT'),\n",
       " ('information', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('our', 'PRP$'),\n",
       " ('corporate', 'JJ'),\n",
       " ('office', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " (\"'ll\", 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('check', 'VB'),\n",
       " ('and', 'CC'),\n",
       " ('update', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('directly', 'RB'),\n",
       " ('about', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('refund', 'NN'),\n",
       " ('So', 'RB'),\n",
       " ('please', 'JJ'),\n",
       " ('expect', 'VBP'),\n",
       " ('an', 'DT'),\n",
       " ('email', 'NN'),\n",
       " ('within', 'IN'),\n",
       " ('two', 'CD'),\n",
       " ('to', 'TO'),\n",
       " ('four', 'CD'),\n",
       " ('business', 'NN'),\n",
       " ('days', 'NNS'),\n",
       " ('Is', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('okay', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('Two', 'CD'),\n",
       " ('to', 'TO'),\n",
       " ('four', 'CD'),\n",
       " ('business', 'NN'),\n",
       " ('days', 'NNS'),\n",
       " ('Yes', 'UH'),\n",
       " ('No', 'DT'),\n",
       " ('worries', 'NNS'),\n",
       " ('I', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('send', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('them', 'PRP'),\n",
       " ('right', 'RB'),\n",
       " ('now', 'RB'),\n",
       " ('Oh', 'UH'),\n",
       " ('really', 'RB'),\n",
       " ('Okay', 'NNP'),\n",
       " ('Alright', 'NNP'),\n",
       " ('alright', 'NN'),\n",
       " ('At', 'IN'),\n",
       " ('first', 'JJ'),\n",
       " ('I', 'PRP'),\n",
       " ('thought', 'VBD'),\n",
       " ('that', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('probably', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('like', 'IN'),\n",
       " ('three', 'CD'),\n",
       " ('to', 'TO'),\n",
       " ('five', 'CD'),\n",
       " ('weeks', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('process', 'NN'),\n",
       " ('Oh', 'UH'),\n",
       " ('no', 'DT'),\n",
       " ('no', 'DT'),\n",
       " ('no', 'DT'),\n",
       " ('Do', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('worry', 'VB'),\n",
       " ('Adam', 'NNP'),\n",
       " ('It', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('only', 'RB'),\n",
       " ('two', 'CD'),\n",
       " ('to', 'TO'),\n",
       " ('four', 'CD'),\n",
       " ('business', 'NN'),\n",
       " ('days', 'NNS'),\n",
       " ('So', 'RB'),\n",
       " ('you', 'PRP'),\n",
       " ('already', 'RB'),\n",
       " ('checked', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('account', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('nothing', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('credited', 'VBN'),\n",
       " ('yet', 'RB'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('card', 'NN'),\n",
       " ('ending', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('753', 'CD'),\n",
       " ('Is', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('right', 'NN'),\n",
       " ('Nothing', 'NN'),\n",
       " ('yet', 'RB'),\n",
       " ('Okay', 'NNP'),\n",
       " ('I', 'PRP'),\n",
       " ('understand', 'VBP'),\n",
       " ('And', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " (\"'ll\", 'MD'),\n",
       " ('go', 'VB'),\n",
       " ('ahead', 'RB'),\n",
       " ('and', 'CC'),\n",
       " ('forward', 'RB'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('details', 'NNS'),\n",
       " ('that', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('here', 'RB'),\n",
       " ('So', 'RB'),\n",
       " ('I', 'PRP'),\n",
       " (\"'ll\", 'MD'),\n",
       " ('send', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('email', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('Adam', 'NNP'),\n",
       " ('underscore', 'RB'),\n",
       " ('Wilson', 'NNP'),\n",
       " ('at', 'IN'),\n",
       " ('MailFence.com', 'NNP'),\n",
       " ('correct', 'NN'),\n",
       " ('Yes', 'UH'),\n",
       " ('that', 'DT'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('right', 'JJ'),\n",
       " ('Alright', 'NNP'),\n",
       " ('thank', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('so', 'RB'),\n",
       " ('much', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('information', 'NN'),\n",
       " ('Adam', 'NNP'),\n",
       " ('I', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('forwarding', 'VBG'),\n",
       " ('this', 'DT'),\n",
       " ('over', 'IN'),\n",
       " ('to', 'TO'),\n",
       " ('our', 'PRP$'),\n",
       " ('corporate', 'JJ'),\n",
       " ('office', 'NN'),\n",
       " ('now', 'RB'),\n",
       " ('And', 'CC'),\n",
       " ('thank', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('again', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('calling', 'VBG'),\n",
       " ('Coats', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Gowns', 'NNP'),\n",
       " ('Is', 'VBZ'),\n",
       " ('there', 'EX'),\n",
       " ('anything', 'NN'),\n",
       " ('else', 'RB'),\n",
       " ('I', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('help', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('with', 'IN'),\n",
       " ('today', 'NN'),\n",
       " ('Oh', 'UH'),\n",
       " ('no', 'DT'),\n",
       " ('that', 'DT'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('all', 'DT'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('You', 'PRP'),\n",
       " (\"'re\", 'VBP'),\n",
       " ('welcome', 'JJ'),\n",
       " ('My', 'PRP$'),\n",
       " ('pleasure', 'NN'),\n",
       " ('Have', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('nice', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('Bye', 'NNP'),\n",
       " ('Alright', 'NNP'),\n",
       " ('thank', 'NN'),\n",
       " ('you', 'PRP')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Thank', 'you', 'for', 'calling', 'Coats', 'and', 'Gowns', 'my', 'name', 'is', 'Sam', 'how', 'can', 'I', 'help', 'you', 'Yes', 'I', 'bought', 'a', 'coat', 'from', 'you', 'guys', 'but', 'I', 'need', 'to', 'return', 'it', 'because', 'it', 'was', 'the', 'wrong', 'size', 'and', 'my', 'size', 'is', 'not', 'available', 'I', 'have', \"n't\", 'received', 'any', 'email', 'from', 'you', 'and', 'I', 'wonder', 'if', 'my', 'payment', 'has', 'been', 'refunded', 'Seems', 'like', 'it', 'does', 'not', 'apply', 'on', 'my', 'account', 'yet', 'I', 'do', 'apologize', 'for', 'the', 'inconvenience', 'but', 'let', 'me', 'go', 'ahead', 'and', 'check', 'if', 'there', 'are', 'some', 'notes', 'in', 'the', 'order', 'details', 'May', 'I', 'ask', 'for', 'the', 'original', 'online', 'order', 'number', 'Okay', 'let', 'me', 'see', 'please', 'wait', 'for', 'a', 'moment', 'Okay', 'I', 'believe', 'it', \"'s\", '017-1425-793', 'Thank', 'you', 'just', 'to', 'verify', 'that', \"'s\", '017-1425-793', 'correct', 'Yes', 'that', \"'s\", 'right', 'I', 'do', 'apologize', 'but', 'the', 'one', 'that', 'you', 'provided', 'is', 'actually', 'not', 'accepting', 'towards', 'our', 'database', 'Do', 'you', 'actually', 'have', 'a', 'number', 'that', 'starts', 'with', '0007', 'or', '7', 'Or', 'can', 'I', 'ask', 'for', 'your', 'first', 'and', 'last', 'name', 'so', 'I', 'can', 'manually', 'check', 'it', 'in', 'our', 'database', 'Yeah', 'I', \"'m\", 'not', 'sure', 'about', 'a', '000', 'something', 'anyway', 'it', \"'s\", 'Adam', 'Wilson', 'Alright', 'thank', 'you', 'So', 'Wilson', 'is', 'spelled', 'as', 'W', 'for', 'Whiskey', 'I', 'for', 'India', 'L', 'for', 'Lima', 'S', 'for', 'Sierra', 'O', 'for', 'Oscar', 'and', 'N', 'for', 'November', 'Is', 'that', 'correct', 'Adam', 'Yes', 'Alright', 'thank', 'you', 'for', 'that', 'information', 'Okay', 'let', 'me', 'just', 'quickly', 'log', 'into', 'a', 'portal', 'and', 'check', 'any', 'notes', 'in', 'your', 'order', 'Do', 'you', 'still', 'have', 'the', 'return', 'tracking', 'from', 'the', 'courier', 'company', 'when', 'you', 'return', 'the', 'item', 'Not', 'sure', 'is', 'it', 'the', '74391', 'That', \"'s\", 'actually', 'the', 'return', 'authorization', 'from', 'Coats', 'and', 'Gowns', 'When', 'you', 'return', 'the', 'item', 'to', 'the', 'courier', 'company', 'for', 'shipping', 'they', 'should', 'have', 'provided', 'you', 'with', 'the', 'return', 'tracking', 'Do', 'you', 'still', 'have', 'that', 'It', \"'s\", 'actually', 'printed', 'in', 'the', 'upper', 'right', 'part', 'of', 'the', 'receipt', 'Okay', 'I', 'probably', 'have', 'to', 'dig', 'it', 'up', 'Okay', 'I', 'imagine', 'I', 'have', 'it', 'somewhere', 'but', 'it', 'might', 'take', 'some', 'time', 'to', 'look', 'for', 'that', 'Oh', 'I', 'see', 'Anyway', 'I', 'tried', 'to', 'search', 'for', 'your', 'name', 'and', 'nothing', 'is', 'coming', 'up', 'Can', 'I', 'ask', 'for', 'the', 'order', 'under', 'your', 'name', 'originally', 'Yes', 'it', \"'s\", 'under', 'my', 'name', 'So', 'it', \"'s\", 'not', 'under', 'Andy', 'or', 'something', 'It', \"'s\", 'Adam', 'Yes', 'exactly', 'Thank', 'you', 'Now', 'what', \"'s\", 'the', 'phone', 'number', 'that', 'you', 'put', 'on', 'the', 'order', 'before', 'Okay', 'probably', 'it', \"'s\", '411-345-0377', 'Thank', 'you', 'It', \"'s\", '411-345-0377', 'is', 'that', 'correct', 'Oh', 'it', \"'s\", '0377', 'Okay', 'and', 'what', \"'s\", 'the', 'email', 'address', 'that', 'you', 'gave', 'when', 'you', 'fill', 'out', 'the', 'order', 'form', 'Okay', 'that', 'should', 'be', 'Adam', 'underscore', 'Wilson', 'at', 'MailFence.com', 'Thank', 'you', 'So', 'again', 'it', \"'s\", 'Adam', 'underscore', 'Wilson', 'at', 'MailFence.com', 'is', 'that', 'correct', 'Yes', 'it', 'is', 'Thank', 'you', 'So', 'Adam', 'underscore', 'Wilson', 'at', 'MailFence.com', 'Okay', 'thank', 'you', 'Now', 'I', 'just', 'want', 'to', 'make', 'sure', 'that', 'I', 'have', 'the', 'correct', 'details', 'Please', 'hold', 'on', 'for', 'a', 'moment', 'while', 'I', 'check', 'on', 'the', 'details', 'here', 'on', 'my', 'end', 'okay', 'Oh', 'sure', 'no', 'problem', 'Alright', 'Okay', 'thank', 'you', 'for', 'patiently', 'waiting', 'Adam', 'Now', 'I', 'can', 'actually', 'see', 'here', 'that', 'you', 'have', 'called', 'to', 'inform', 'us', 'that', 'you', \"'d\", 'like', 'to', 'return', 'the', 'item', 'on', 'the', '15th', 'of', 'November', 'Is', 'that', 'correct', 'Yes', 'Now', 'did', 'you', 'return', 'the', 'item', 'to', 'the', 'courier', 'company', 'on', 'the', 'same', 'day', 'that', 'you', 'called', 'Probably', 'close', 'to', 'it', 'I', \"'m\", 'not', 'really', 'sure', 'if', 'it', \"'s\", 'on', 'the', 'same', 'day', 'though', 'but', 'probably', 'just', 'close', 'to', 'that', 'day', 'I', 'understand', 'However', 'upon', 'checking', 'the', 'date', 'that', 'you', 'actually', 'called', 'in', 'for', 'the', 'return', 'it', \"'s\", 'already', 'beyond', 'the', 'time', 'frame', 'that', 'we', 'asked', 'for', 'refunds', 'So', 'what', 'we', \"'ll\", 'do', 'is', 'I', \"'ll\", 'go', 'ahead', 'and', 'forward', 'this', 'information', 'to', 'our', 'corporate', 'office', 'and', 'I', \"'ll\", 'have', 'them', 'check', 'and', 'update', 'you', 'directly', 'about', 'the', 'refund', 'So', 'please', 'expect', 'an', 'email', 'within', 'two', 'to', 'four', 'business', 'days', 'Is', 'that', 'okay', 'with', 'you', 'Two', 'to', 'four', 'business', 'days', 'Yes', 'No', 'worries', 'I', 'will', 'send', 'it', 'to', 'them', 'right', 'now', 'Oh', 'really', 'Okay', 'Alright', 'alright', 'At', 'first', 'I', 'thought', 'that', 'it', 'will', 'probably', 'be', 'like', 'three', 'to', 'five', 'weeks', 'to', 'process', 'Oh', 'no', 'no', 'no', 'Do', \"n't\", 'worry', 'Adam', 'It', \"'s\", 'only', 'two', 'to', 'four', 'business', 'days', 'So', 'you', 'already', 'checked', 'your', 'account', 'and', 'nothing', 'has', 'been', 'credited', 'yet', 'on', 'the', 'card', 'ending', 'in', '753', 'Is', 'that', 'right', 'Nothing', 'yet', 'Okay', 'I', 'understand', 'And', 'I', \"'ll\", 'go', 'ahead', 'and', 'forward', 'in', 'the', 'details', 'that', 'I', 'have', 'here', 'So', 'I', \"'ll\", 'send', 'the', 'email', 'to', 'Adam', 'underscore', 'Wilson', 'at', 'MailFence.com', 'correct', 'Yes', 'that', \"'s\", 'right', 'Alright', 'thank', 'you', 'so', 'much', 'for', 'that', 'information', 'Adam', 'I', 'will', 'be', 'forwarding', 'this', 'over', 'to', 'our', 'corporate', 'office', 'now', 'And', 'thank', 'you', 'again', 'for', 'calling', 'Coats', 'and', 'Gowns', 'Is', 'there', 'anything', 'else', 'I', 'can', 'help', 'you', 'with', 'today', 'Oh', 'no', 'that', \"'s\", 'all', 'Thank', 'you', 'You', \"'re\", 'welcome', 'My', 'pleasure', 'Have', 'a', 'nice', 'day', 'Bye', 'Alright', 'thank', 'you'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.2349368318756074, subjectivity=0.46441528992549386)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractive Summarization with gensim\n",
    "from gensim.summarization import summarize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Summarize the text (ratio controls the length of the summary)\n",
    "summary = summarize(analysis, ratio=0.2)\n",
    "\n",
    "# Print the summary\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (1024). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m input_ids \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(transcript1, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, max_length\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m \u001b[39m# Generate a summary (adjust the max_length parameter for desired summary length)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m summary_ids \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(input_ids, max_length\u001b[39m=\u001b[39;49m\u001b[39m1500\u001b[39;49m, num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, length_penalty\u001b[39m=\u001b[39;49m\u001b[39m2.0\u001b[39;49m, min_length\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, no_repeat_ngram_size\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, early_stopping\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     15\u001b[0m \u001b[39m# Decode and print the summary\u001b[39;00m\n\u001b[0;32m     16\u001b[0m summary_text \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mdecode(summary_ids[\u001b[39m0\u001b[39m], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\transformers\\generation\\utils.py:1538\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[0;32m   1532\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1533\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnum_return_sequences has to be 1 when doing greedy search, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1534\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut is \u001b[39m\u001b[39m{\u001b[39;00mgeneration_config\u001b[39m.\u001b[39mnum_return_sequences\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1535\u001b[0m         )\n\u001b[0;32m   1537\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[1;32m-> 1538\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[0;32m   1539\u001b[0m         input_ids,\n\u001b[0;32m   1540\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[0;32m   1541\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[0;32m   1542\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[0;32m   1543\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[0;32m   1544\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[0;32m   1545\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[0;32m   1546\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[0;32m   1547\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[0;32m   1548\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[0;32m   1549\u001b[0m     )\n\u001b[0;32m   1551\u001b[0m \u001b[39melif\u001b[39;00m is_contrastive_search_gen_mode:\n\u001b[0;32m   1552\u001b[0m     \u001b[39mif\u001b[39;00m generation_config\u001b[39m.\u001b[39mnum_return_sequences \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\transformers\\generation\\utils.py:2362\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2359\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2361\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2362\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[0;32m   2363\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[0;32m   2364\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   2365\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   2366\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   2367\u001b[0m )\n\u001b[0;32m   2369\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2370\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1076\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1068\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1074\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1076\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[0;32m   1077\u001b[0m     input_ids,\n\u001b[0;32m   1078\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1079\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1080\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1081\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1082\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1083\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1084\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1085\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m   1086\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1087\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1088\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1089\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1090\u001b[0m )\n\u001b[0;32m   1091\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1093\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:844\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    843\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwte(input_ids)\n\u001b[1;32m--> 844\u001b[0m position_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwpe(position_ids)\n\u001b[0;32m    845\u001b[0m hidden_states \u001b[39m=\u001b[39m inputs_embeds \u001b[39m+\u001b[39m position_embeds\n\u001b[0;32m    847\u001b[0m \u001b[39mif\u001b[39;00m token_type_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[0;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[0;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[1;32me:\\pythoninstall\\Lib\\site-packages\\torch\\nn\\functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "# Abstractive Summarization with transformers (GPT-2)\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "\n",
    "# Tokenize the input text\n",
    "input_ids = tokenizer.encode(transcript1, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "# Generate a summary (adjust the max_length parameter for desired summary length)\n",
    "summary_ids = model.generate(input_ids, max_length=150, num_return_sequences=1, length_penalty=2.0, min_length=30, no_repeat_ngram_size=2, early_stopping=True)\n",
    "\n",
    "# Decode and print the summary\n",
    "summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(summary_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
